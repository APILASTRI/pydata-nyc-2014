{
 "metadata": {
  "name": "",
  "signature": "sha256:94f1779ee5c0755434bcb84d835e55e9e90ff4f3aaca512b1cb7f64aa0e8f343"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we learn something so far, that is machine learning is not only applying an algorithm and get the predictions. It has quite a lot of different and moving parts for a given problem. Steps(feature extraction, feature selection, classifier, evaluation) follows a sequential order, though. Would it be perfect if we could wrap all of the steps in one object and then do the parameter search(i.e. grid parameter search) for cross validation in that object. Further, if we have two estimators in the __pipeline__(say we apply PCA to reduce dimension in the input and then apply SVM), we would need only once to use the `fit` function in the estimator. Pipeline automatically applies the correct steps for you to get the correct output at the end of the pipeline. Still not convinced? What if I say, serializing one `pipeline` instead of serializing `vectorizer`, `feature_selector` and `classifier` separately and then deploying into production makes much easier. This is a quick win for pipeline. Let's see how one might use it in text classification."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import csv\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import os\n",
      "from sklearn import cross_validation\n",
      "from sklearn import ensemble\n",
      "from sklearn.feature_extraction import text\n",
      "from sklearn import feature_extraction\n",
      "from sklearn import feature_selection\n",
      "from sklearn import linear_model\n",
      "from sklearn import metrics\n",
      "from sklearn import naive_bayes\n",
      "from sklearn import pipeline\n",
      "from sklearn import svm\n",
      "from sklearn import tree\n",
      "\n",
      "_DATA_DIR = 'data'\n",
      "_NYT_DATA_PATH = os.path.join(_DATA_DIR, 'nyt_title_data.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(_NYT_DATA_PATH) as nyt:\n",
      "    nyt_data = []\n",
      "    nyt_labels = []\n",
      "    csv_reader = csv.reader(nyt)\n",
      "    for line in csv_reader:\n",
      "      nyt_labels.append(int(line[0]))\n",
      "      nyt_data.append(line[1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.array([''.join(el) for el in nyt_data])\n",
      "y = np.array([el for el in nyt_labels])\n",
      "\n",
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y)\n",
      "\n",
      "vectorizer = text.TfidfVectorizer(min_df=2, \n",
      " ngram_range=(1, 2), \n",
      " stop_words='english', \n",
      " strip_accents='unicode', \n",
      " norm='l2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Let's Create our pipeline"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipe = pipeline.Pipeline([(\"vectorizer\", vectorizer), (\"svm\", linear_model.RidgeClassifier())])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pipe.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "Pipeline(steps=[('vectorizer', TfidfVectorizer(analyzer=u'word', binary=False, charset=None,\n",
        "        charset_error=None, decode_error=u'strict',\n",
        "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
        "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
        "        ngram_range=(1, 2)...copy_X=True, fit_intercept=True,\n",
        "        max_iter=None, normalize=False, solver='auto', tol=0.001))])"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "metrics.accuracy_score(pipe.predict(X_test), y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "0.64695009242144175"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}