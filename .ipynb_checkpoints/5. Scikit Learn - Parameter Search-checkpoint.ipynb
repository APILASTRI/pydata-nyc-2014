{
 "metadata": {
  "name": "",
  "signature": "sha256:4662e0c0cfa9e9ea774f948f1c60fcc393f18445c69244e24d03725860a7c933"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For every classifier, there are __a lot of__ parameters to be optimized in Scikit-Learn to get an optimal accuracy for the classifier in the cross-validattion dataset. You could always try and fail and see which parameters work for best but it is time consuming(computation, storage and reporting) and cumbersome in general if you want to handle the parameter search by yourself. Consider these parameters an extra burden when you try to choose an optimal classifier out of multiple classifiers."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Scikit-learn provides a grid search with cross validation so that when you do the parameter search in `GridSearchCV`, it automatically finds the best parameters tested on a cross-validation so you do not have to search the parameters in different folds."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One thing to note is that it may take a lot of time to do on a regular machine if you have a lot of parameters to try as the number of parameters will be a combinatorial of those parameters. So you may want to use a powerful and multicore machine to do the grid search in the parameter space. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline \n",
      "\n",
      "import matplotlib as mlp\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import sklearn\n",
      "from sklearn import cross_validation\n",
      "from sklearn import datasets\n",
      "import time\n",
      "\n",
      "plt.style.use('fivethirtyeight')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "california_housing = datasets.california_housing.fetch_california_housing()\n",
      "california_housing_data = california_housing['data']\n",
      "california_housing_labels = california_housing['target']# 'target' variables\n",
      "california_housing_feature_names = california_housing['feature_names']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train, X_test, y_train, y_test = cross_validation.train_test_split(california_housing_data,\n",
      "                                                    california_housing_labels,\n",
      "                                                    test_size=0.2,\n",
      "                                                    random_state=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to create a grid search object, it is necessary to pass the estimator, parameters to optimize for that estimator, optionally you could pass `n_job` in order to parallellize the parameter search. Grid search in parameter space is embarrasingly parallel by nature as different parameter combinations are independent from each other. You could also pass different scoring functions if you want to use another scoring function to optimize the best parameters for your classifier."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn import ensemble\n",
      "\n",
      "\n",
      "param_grid = {\n",
      "              'learning_rate': [0.1, 0.05, 0.01],\n",
      "              'max_depth': [4, 6],\n",
      "              'min_samples_leaf': [3, 9, 15],\n",
      "              'n_estimators': [1000, 2000, 3000],\n",
      "              }\n",
      "\n",
      "est = ensemble.GradientBoostingRegressor()\n",
      "\n",
      "start_time = time.time()\n",
      "gs_cv = GridSearchCV(est, param_grid, n_jobs=4).fit(X_train, y_train)\n",
      "end_time = time.time()\n",
      "\n",
      "print('It took {} seconds'.format(end_time - start_time))\n",
      "# best hyperparameter setting\n",
      "gs_cv.best_params_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "It took 4989.2835319 seconds\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "{'learning_rate': 0.05,\n",
        " 'max_depth': 6,\n",
        " 'min_samples_leaf': 15,\n",
        " 'n_estimators': 2000}"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you want to get scores for each different parameter combination, `grid_scores_` attribute of GridSearch object provides a nice way to provide all of the scores for each parameter combination."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gs_cv.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "[mean: 0.83466, std: 0.00261, params: {'n_estimators': 1000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 3},\n",
        " mean: 0.83573, std: 0.00256, params: {'n_estimators': 2000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 3},\n",
        " mean: 0.83524, std: 0.00241, params: {'n_estimators': 3000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 3},\n",
        " mean: 0.83512, std: 0.00269, params: {'n_estimators': 1000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 9},\n",
        " mean: 0.83493, std: 0.00243, params: {'n_estimators': 2000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 9},\n",
        " mean: 0.83366, std: 0.00250, params: {'n_estimators': 3000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 9},\n",
        " mean: 0.83669, std: 0.00174, params: {'n_estimators': 1000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 15},\n",
        " mean: 0.83715, std: 0.00267, params: {'n_estimators': 2000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 15},\n",
        " mean: 0.83589, std: 0.00265, params: {'n_estimators': 3000, 'learning_rate': 0.1, 'max_depth': 4, 'min_samples_leaf': 15},\n",
        " mean: 0.83717, std: 0.00129, params: {'n_estimators': 1000, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 3},\n",
        " mean: 0.83668, std: 0.00130, params: {'n_estimators': 2000, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 3},\n",
        " mean: 0.83623, std: 0.00132, params: {'n_estimators': 3000, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 3},\n",
        " mean: 0.83684, std: 0.00215, params: {'n_estimators': 1000, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 9},\n",
        " mean: 0.83615, std: 0.00189, params: {'n_estimators': 2000, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 9},\n",
        " mean: 0.83536, std: 0.00185, params: {'n_estimators': 3000, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 9},\n",
        " mean: 0.83755, std: 0.00156, params: {'n_estimators': 1000, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 15},\n",
        " mean: 0.83603, std: 0.00126, params: {'n_estimators': 2000, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 15},\n",
        " mean: 0.83504, std: 0.00145, params: {'n_estimators': 3000, 'learning_rate': 0.1, 'max_depth': 6, 'min_samples_leaf': 15},\n",
        " mean: 0.83157, std: 0.00204, params: {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 3},\n",
        " mean: 0.83440, std: 0.00239, params: {'n_estimators': 2000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 3},\n",
        " mean: 0.83548, std: 0.00219, params: {'n_estimators': 3000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 3},\n",
        " mean: 0.83205, std: 0.00182, params: {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 9},\n",
        " mean: 0.83496, std: 0.00233, params: {'n_estimators': 2000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 9},\n",
        " mean: 0.83548, std: 0.00208, params: {'n_estimators': 3000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 9},\n",
        " mean: 0.83380, std: 0.00185, params: {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 15},\n",
        " mean: 0.83746, std: 0.00270, params: {'n_estimators': 2000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 15},\n",
        " mean: 0.83832, std: 0.00334, params: {'n_estimators': 3000, 'learning_rate': 0.05, 'max_depth': 4, 'min_samples_leaf': 15},\n",
        " mean: 0.83705, std: 0.00292, params: {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 3},\n",
        " mean: 0.83814, std: 0.00326, params: {'n_estimators': 2000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 3},\n",
        " mean: 0.83796, std: 0.00331, params: {'n_estimators': 3000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 3},\n",
        " mean: 0.83717, std: 0.00246, params: {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 9},\n",
        " mean: 0.83759, std: 0.00200, params: {'n_estimators': 2000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 9},\n",
        " mean: 0.83729, std: 0.00184, params: {'n_estimators': 3000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 9},\n",
        " mean: 0.83903, std: 0.00160, params: {'n_estimators': 1000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 15},\n",
        " mean: 0.83928, std: 0.00206, params: {'n_estimators': 2000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 15},\n",
        " mean: 0.83862, std: 0.00207, params: {'n_estimators': 3000, 'learning_rate': 0.05, 'max_depth': 6, 'min_samples_leaf': 15},\n",
        " mean: 0.80415, std: 0.00012, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 3},\n",
        " mean: 0.82043, std: 0.00123, params: {'n_estimators': 2000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 3},\n",
        " mean: 0.82666, std: 0.00157, params: {'n_estimators': 3000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 3},\n",
        " mean: 0.80566, std: 0.00118, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 9},\n",
        " mean: 0.82172, std: 0.00089, params: {'n_estimators': 2000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 9},\n",
        " mean: 0.82785, std: 0.00182, params: {'n_estimators': 3000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 9},\n",
        " mean: 0.80542, std: 0.00182, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 15},\n",
        " mean: 0.82148, std: 0.00052, params: {'n_estimators': 2000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 15},\n",
        " mean: 0.82741, std: 0.00095, params: {'n_estimators': 3000, 'learning_rate': 0.01, 'max_depth': 4, 'min_samples_leaf': 15},\n",
        " mean: 0.82477, std: 0.00188, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 3},\n",
        " mean: 0.83267, std: 0.00157, params: {'n_estimators': 2000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 3},\n",
        " mean: 0.83506, std: 0.00192, params: {'n_estimators': 3000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 3},\n",
        " mean: 0.82550, std: 0.00247, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 9},\n",
        " mean: 0.83371, std: 0.00170, params: {'n_estimators': 2000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 9},\n",
        " mean: 0.83644, std: 0.00171, params: {'n_estimators': 3000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 9},\n",
        " mean: 0.82603, std: 0.00174, params: {'n_estimators': 1000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 15},\n",
        " mean: 0.83393, std: 0.00144, params: {'n_estimators': 2000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 15},\n",
        " mean: 0.83648, std: 0.00187, params: {'n_estimators': 3000, 'learning_rate': 0.01, 'max_depth': 6, 'min_samples_leaf': 15}]"
       ]
      }
     ],
     "prompt_number": 9
    }
   ],
   "metadata": {}
  }
 ]
}